name: github.com/Dao-AILab/flash-attention
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  build:
    strategy:
      matrix:
        version: [main]
        os: [ubuntu-24.04, ubuntu-24.04-arm]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      - uses: Jimver/cuda-toolkit@master
      - run: |
          git clone https://github.com/Dao-AILab/flash-attention
          cd flash-attention/hopper
          pip install ninja packaging setuptools
          MAX_JOBS=2 python setup.py bdist_wheel
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: flash-attention-${{ matrix.os }}-${{ matrix.version }}
          path: |
            flash-attention/hopper/dist/*.whl
