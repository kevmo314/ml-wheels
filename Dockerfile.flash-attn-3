FROM nvidia/cuda:13.0.1-cudnn-devel-ubuntu24.04 AS build

ARG VERSION=d063b333baae9c6066fe003be18c426eb602cbf3
ARG MAX_JOBS=40

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential \
    git \
    curl \
    ca-certificates && \
    rm -rf /var/lib/apt/lists/*

# Install uv and Python 3.14 free-threaded
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.local/bin:$PATH"
RUN uv python install cpython-3.14.0+freethreaded

ENV MAX_JOBS=${MAX_JOBS}

RUN uv venv /opt/venv --python cpython-3.14.0+freethreaded
ENV VIRTUAL_ENV=/opt/venv
ENV PATH="/opt/venv/bin:$PATH"

RUN uv pip install --no-cache-dir pip ninja packaging numpy setuptools wheel psutil && \
    uv pip install torch==2.10.0.dev20251118+cu130 --index-url https://download.pytorch.org/whl/nightly/cu130

RUN git clone https://github.com/Dao-AILab/flash-attention && \
    cd flash-attention/hopper && \
    git checkout ${VERSION} && \
    # Disable abi3/limited API for free-threaded Python compatibility \
    sed -i 's/, "-DPy_LIMITED_API=0x03090000"//g' setup.py && \
    sed -i 's/py_limited_api=True/py_limited_api=False/g' setup.py && \
    sed -i 's/"py_limited_api": "cp39"//g' setup.py && \
    python3 setup.py bdist_wheel

FROM scratch

COPY --from=build /flash-attention/hopper/dist/* .
